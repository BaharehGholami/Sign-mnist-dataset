{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of last-sign_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2H63afLxduU"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\"username\":\"baharehgholami\",\"key\":\"6fc71ac351606882ff7c1146be58f4b6\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d datamunge/sign-language-mnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URQZeXuhxrYl",
        "outputId": "4786e4d2-10a6-4882-da67-32e8d9fb3535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sign-language-mnist.zip to /content\n",
            " 53% 33.0M/62.6M [00:00<00:00, 168MB/s] \n",
            "100% 62.6M/62.6M [00:00<00:00, 206MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/sign-language-mnist.zip"
      ],
      "metadata": {
        "id": "P2mRpowzx09a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d134e03-6429-4135-edfa-dd2b208f53a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/sign-language-mnist.zip\n",
            "  inflating: amer_sign2.png          \n",
            "  inflating: amer_sign3.png          \n",
            "  inflating: american_sign_language.PNG  \n",
            "  inflating: sign_mnist_test.csv     \n",
            "  inflating: sign_mnist_test/sign_mnist_test.csv  \n",
            "  inflating: sign_mnist_train.csv    \n",
            "  inflating: sign_mnist_train/sign_mnist_train.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torchvision.transforms as transforms \n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim "
      ],
      "metadata": {
        "id": "Tg9KcvZTyYrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv(\"/content/sign_mnist_train/sign_mnist_train.csv\")\n",
        "test=pd.read_csv(\"/content/sign_mnist_test/sign_mnist_test.csv\")"
      ],
      "metadata": {
        "id": "fDNwlLoKyd6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(np.unique(train[\"label\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56OA2oYFgHw4",
        "outputId": "73e77433-9c9a-4f6b-c40f-3ef7255daa60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(train[\"label\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd_NC_9Jyk1N",
        "outputId": "4ac82a27-1709-4f4e-9f99-b010b27f53f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.from_numpy(train.iloc[:,1:].values[3].reshape(1,28,28)).dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuOrIuYXg4pT",
        "outputId": "e59b13e9-6746-4ae9-b8f5-d1b78d673b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(train.iloc[:,0].values[7]).dtype\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtRDabc7gptx",
        "outputId": "ed0cf2cb-bd73-463a-b2c9-d0b20d60c2c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import linear\n",
        "class Model(nn.Module):\n",
        "   def __init__(self):\n",
        "      super(Model,self).__init__()\n",
        "      self.sequential=nn.Sequential(nn.Conv2d(1,32,(2,2),padding='same',stride=1),\n",
        "                                    nn.Conv2d(32,64,(2,2),padding=\"same\"),\n",
        "                                    nn.MaxPool2d(2),\n",
        "                                    nn.Conv2d(64,128,(3,3),padding='same'),\n",
        "                                    nn.Conv2d(128,256,(3,3),padding='same'),\n",
        "                                    nn.MaxPool2d(2),nn.Flatten(),\n",
        "                                    nn.Linear(7*7*256,800),\n",
        "                                    nn.Dropout(0.2),\n",
        "                                    nn.Linear(800,100),\n",
        "                                    nn.Dropout(0.5),\n",
        "                                    nn.Linear(100,25),\n",
        "                                    nn.Softmax())\n",
        "   def forward(self, x):\n",
        "       x=self.sequential(x)\n",
        "       return x\n",
        "\n",
        "      "
      ],
      "metadata": {
        "id": "kUyAtpUt55Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(         \n",
        "            nn.Conv2d(\n",
        "                in_channels=1,              \n",
        "                out_channels=16,            \n",
        "                kernel_size=5,              \n",
        "                stride=1,                   \n",
        "                padding=2,                  \n",
        "            ),                              \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=2),    \n",
        "        )\n",
        "        self.conv2 = nn.Sequential(         \n",
        "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(2),                \n",
        "        )\n",
        "        # fully connected layer, output 10 classes\n",
        "        self.out = nn.Linear(32 * 7 * 7, 25)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "        x = x.view(x.size(0), -1)       \n",
        "        output = self.out(x)\n",
        "        return output  "
      ],
      "metadata": {
        "id": "uNkfzTh-XOWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN()(torch.randn(32,1,28,28)).shape"
      ],
      "metadata": {
        "id": "cr8aa0MBDJMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fdd8451-273e-41d0-98b3-a85b600b1917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN()(torch.randn(32,1,28,28)).argmax(axis=1)"
      ],
      "metadata": {
        "id": "R2EuuwGaDZPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e0afc4-d9f8-4a6f-e56e-ce191f928359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12, 21, 12,  6, 12, 12, 12, 12, 12, 12, 12, 21, 12, 21, 12, 12, 12, 12,\n",
              "        12, 12, 12, 21, 12,  0, 12, 12, 12, 12, 12, 12, 12, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "dtype = torch.FloatTensor\n",
        "def train_fn(model,optimizer,dataloader,loss_fn,device,epoch):\n",
        "  model.to(device) \n",
        "  model.train()\n",
        "  loss_step=0\n",
        "  Loss_final=0\n",
        "  total_step=len(dataloader)\n",
        "  for i,(x,y) in enumerate(dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    #print(x.type)\n",
        "    x=(x.type(dtype)).to(device)\n",
        "    y=y.to(device)\n",
        "    #x=x.to(device)\n",
        "    #y=y.to(device)\n",
        "    pred=model(x)\n",
        "    loss_step=loss_fn(pred,y)\n",
        "    Loss_final+=loss_step.item()\n",
        "    loss_step.backward()\n",
        "    optimizer.step()\n",
        "    if (i+1) % 100 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                       .format(epoch + 1, EPOCHS, i + 1, total_step, loss_step.item()))\n",
        "    \n",
        "\n",
        "  Loss_final=Loss_final/len(dataloader)\n",
        "  return Loss_final\n",
        "\n",
        "def valid_fn(model,optimizer,dataloader,loss_fn,device):\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  num_correct=0\n",
        "  num_samples = 0\n",
        "  #prediction_valid=[]\n",
        "  #Loss_val=0\n",
        "  for x,y in dataloader:\n",
        "    x=(x.type(dtype)).to(device)\n",
        "    y=y.to(device)\n",
        "    with torch.no_grad():\n",
        "      pred=model(x)\n",
        "    #loss=loss_fn(pred,y)\n",
        "    #Loss_val+=loss.item()\n",
        "    #prediction_valid.append(pred)\n",
        "    predict_arg=pred.argmax(axis=1)\n",
        "    num_correct+=(predict_arg==y).sum()\n",
        "    num_samples+=pred.size(0)\n",
        "  print(f\"Got {num_correct} / {num_samples} with accuracy {float((num_correct)/float(num_samples))*100:.2f}\")"
      ],
      "metadata": {
        "id": "s-1AmsPPDl5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HyperParameters\n",
        "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "EPOCHS = 25\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 1e-5\n",
        "NFOLDS = 5\n",
        "EARLY_STOPPING_STEPS = 10\n",
        "EARLY_STOP = False"
      ],
      "metadata": {
        "id": "RJcXjo_YIKtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class image_dataset(Dataset):\n",
        "  def __init__(self,data,transform=False):\n",
        "      super().__init__()\n",
        "      self.data=data\n",
        "      self.transform=transform\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.data.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        features=self.data.iloc[:,1:].values[index].reshape(1,28,28)\n",
        "        targets=self.data.iloc[:,0].values[index]\n",
        "        #targets=torch.Tensor(targets)\n",
        "        if self.transform:\n",
        "          features=self.standard(features)\n",
        "          features=torch.from_numpy(features)\n",
        "        return features, targets\n",
        "  def standard(self,x): #x:torch.float64\n",
        "        return ((x-159.29)/48.76)"
      ],
      "metadata": {
        "id": "gEduBcCfkwbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset,valset=train_test_split(train,test_size=0.1,random_state=66)\n",
        "\n",
        "trainset2=image_dataset(trainset,transform=True)\n",
        "train_loader=DataLoader(trainset2,batch_size=32,shuffle=True)\n",
        "\n",
        "valset2=image_dataset(valset,transform=True)\n",
        "val_loader=DataLoader(valset2,batch_size=32,shuffle=False)\n",
        "\n",
        "model=CNN()\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "DEVICE=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "best_loss=np.inf\n",
        "steps=0\n",
        "optimizer=optim.Adam(model.parameters(),lr=LEARNING_RATE,weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  loss=train_fn(model=model,dataloader=train_loader,loss_fn=loss_fn,optimizer=optimizer,device=DEVICE,epoch=epoch)\n",
        "  print(f'train loss at epoch {epoch} is {loss}')\n",
        "  if loss<best_loss:\n",
        "    best_loss=loss\n",
        "    torch.save(model.state_dict(),\"model.pth\")\n",
        "  elif EARLY_STOP == False:\n",
        "    steps+=1\n",
        "    if (steps>EARLY_STOPPING_STEPS):\n",
        "      break\n",
        "\n",
        "model=CNN()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "model.eval()\n",
        "valid_fn(model,optimizer,val_loader,loss_fn,DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8LBhhHIIWWl",
        "outputId": "03438b41-a995-47a5-cfe9-f041ba71e35e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], Step [100/773], Loss: 0.8359\n",
            "Epoch [1/25], Step [200/773], Loss: 0.4561\n",
            "Epoch [1/25], Step [300/773], Loss: 0.2333\n",
            "Epoch [1/25], Step [400/773], Loss: 0.0485\n",
            "Epoch [1/25], Step [500/773], Loss: 0.0354\n",
            "Epoch [1/25], Step [600/773], Loss: 0.0313\n",
            "Epoch [1/25], Step [700/773], Loss: 0.0153\n",
            "train loss at epoch 0 is 0.3625246050016398\n",
            "Epoch [2/25], Step [100/773], Loss: 0.0015\n",
            "Epoch [2/25], Step [200/773], Loss: 0.0022\n",
            "Epoch [2/25], Step [300/773], Loss: 0.0013\n",
            "Epoch [2/25], Step [400/773], Loss: 0.1378\n",
            "Epoch [2/25], Step [500/773], Loss: 0.2448\n",
            "Epoch [2/25], Step [600/773], Loss: 0.0032\n",
            "Epoch [2/25], Step [700/773], Loss: 0.0016\n",
            "train loss at epoch 1 is 0.018697182435572765\n",
            "Epoch [3/25], Step [100/773], Loss: 0.0015\n",
            "Epoch [3/25], Step [200/773], Loss: 0.0006\n",
            "Epoch [3/25], Step [300/773], Loss: 0.0004\n",
            "Epoch [3/25], Step [400/773], Loss: 0.0003\n",
            "Epoch [3/25], Step [500/773], Loss: 0.0006\n",
            "Epoch [3/25], Step [600/773], Loss: 0.0001\n",
            "Epoch [3/25], Step [700/773], Loss: 0.0005\n",
            "train loss at epoch 2 is 0.0005254467591033829\n",
            "Epoch [4/25], Step [100/773], Loss: 0.0002\n",
            "Epoch [4/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [4/25], Step [300/773], Loss: 0.0003\n",
            "Epoch [4/25], Step [400/773], Loss: 0.0001\n",
            "Epoch [4/25], Step [500/773], Loss: 0.0001\n",
            "Epoch [4/25], Step [600/773], Loss: 0.0001\n",
            "Epoch [4/25], Step [700/773], Loss: 0.0001\n",
            "train loss at epoch 3 is 0.00019881670505952171\n",
            "Epoch [5/25], Step [100/773], Loss: 0.0001\n",
            "Epoch [5/25], Step [200/773], Loss: 0.0002\n",
            "Epoch [5/25], Step [300/773], Loss: 0.0001\n",
            "Epoch [5/25], Step [400/773], Loss: 0.0003\n",
            "Epoch [5/25], Step [500/773], Loss: 0.0001\n",
            "Epoch [5/25], Step [600/773], Loss: 0.0001\n",
            "Epoch [5/25], Step [700/773], Loss: 0.0001\n",
            "train loss at epoch 4 is 0.00011199331928921362\n",
            "Epoch [6/25], Step [100/773], Loss: 0.0001\n",
            "Epoch [6/25], Step [200/773], Loss: 0.0001\n",
            "Epoch [6/25], Step [300/773], Loss: 0.0001\n",
            "Epoch [6/25], Step [400/773], Loss: 0.0001\n",
            "Epoch [6/25], Step [500/773], Loss: 0.0001\n",
            "Epoch [6/25], Step [600/773], Loss: 0.0000\n",
            "Epoch [6/25], Step [700/773], Loss: 0.0001\n",
            "train loss at epoch 5 is 7.286466866995611e-05\n",
            "Epoch [7/25], Step [100/773], Loss: 0.0000\n",
            "Epoch [7/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [7/25], Step [300/773], Loss: 0.0001\n",
            "Epoch [7/25], Step [400/773], Loss: 0.0000\n",
            "Epoch [7/25], Step [500/773], Loss: 0.0001\n",
            "Epoch [7/25], Step [600/773], Loss: 0.0001\n",
            "Epoch [7/25], Step [700/773], Loss: 0.0000\n",
            "train loss at epoch 6 is 4.9994412119507434e-05\n",
            "Epoch [8/25], Step [100/773], Loss: 0.0000\n",
            "Epoch [8/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [8/25], Step [300/773], Loss: 0.0001\n",
            "Epoch [8/25], Step [400/773], Loss: 0.0000\n",
            "Epoch [8/25], Step [500/773], Loss: 0.0001\n",
            "Epoch [8/25], Step [600/773], Loss: 0.0000\n",
            "Epoch [8/25], Step [700/773], Loss: 0.0000\n",
            "train loss at epoch 7 is 3.690335349663467e-05\n",
            "Epoch [9/25], Step [100/773], Loss: 0.0000\n",
            "Epoch [9/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [9/25], Step [300/773], Loss: 0.0001\n",
            "Epoch [9/25], Step [400/773], Loss: 0.0000\n",
            "Epoch [9/25], Step [500/773], Loss: 0.0000\n",
            "Epoch [9/25], Step [600/773], Loss: 0.0000\n",
            "Epoch [9/25], Step [700/773], Loss: 0.0000\n",
            "train loss at epoch 8 is 3.0119890461372387e-05\n",
            "Epoch [10/25], Step [100/773], Loss: 0.0000\n",
            "Epoch [10/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [10/25], Step [300/773], Loss: 0.0000\n",
            "Epoch [10/25], Step [400/773], Loss: 0.0000\n",
            "Epoch [10/25], Step [500/773], Loss: 0.0001\n",
            "Epoch [10/25], Step [600/773], Loss: 0.0013\n",
            "Epoch [10/25], Step [700/773], Loss: 0.0313\n",
            "train loss at epoch 9 is 0.03001908223169569\n",
            "Epoch [11/25], Step [100/773], Loss: 0.0013\n",
            "Epoch [11/25], Step [200/773], Loss: 0.0001\n",
            "Epoch [11/25], Step [300/773], Loss: 0.0002\n",
            "Epoch [11/25], Step [400/773], Loss: 0.0005\n",
            "Epoch [11/25], Step [500/773], Loss: 0.0002\n",
            "Epoch [11/25], Step [600/773], Loss: 0.0002\n",
            "Epoch [11/25], Step [700/773], Loss: 0.0003\n",
            "train loss at epoch 10 is 0.0016940184221230755\n",
            "Epoch [12/25], Step [100/773], Loss: 0.0001\n",
            "Epoch [12/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [12/25], Step [300/773], Loss: 0.0001\n",
            "Epoch [12/25], Step [400/773], Loss: 0.0000\n",
            "Epoch [12/25], Step [500/773], Loss: 0.0000\n",
            "Epoch [12/25], Step [600/773], Loss: 0.0000\n",
            "Epoch [12/25], Step [700/773], Loss: 0.0000\n",
            "train loss at epoch 11 is 0.00010654726326777918\n",
            "Epoch [13/25], Step [100/773], Loss: 0.0001\n",
            "Epoch [13/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [13/25], Step [300/773], Loss: 0.0000\n",
            "Epoch [13/25], Step [400/773], Loss: 0.0000\n",
            "Epoch [13/25], Step [500/773], Loss: 0.0000\n",
            "Epoch [13/25], Step [600/773], Loss: 0.0000\n",
            "Epoch [13/25], Step [700/773], Loss: 0.0000\n",
            "train loss at epoch 12 is 5.853207557310415e-05\n",
            "Epoch [14/25], Step [100/773], Loss: 0.0000\n",
            "Epoch [14/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [14/25], Step [300/773], Loss: 0.0000\n",
            "Epoch [14/25], Step [400/773], Loss: 0.0001\n",
            "Epoch [14/25], Step [500/773], Loss: 0.0001\n",
            "Epoch [14/25], Step [600/773], Loss: 0.0000\n",
            "Epoch [14/25], Step [700/773], Loss: 0.0001\n",
            "train loss at epoch 13 is 3.7929236590030596e-05\n",
            "Epoch [15/25], Step [100/773], Loss: 0.0000\n",
            "Epoch [15/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [15/25], Step [300/773], Loss: 0.0000\n",
            "Epoch [15/25], Step [400/773], Loss: 0.0000\n",
            "Epoch [15/25], Step [500/773], Loss: 0.0000\n",
            "Epoch [15/25], Step [600/773], Loss: 0.0000\n",
            "Epoch [15/25], Step [700/773], Loss: 0.0000\n",
            "train loss at epoch 14 is 2.7004816479730327e-05\n",
            "Epoch [16/25], Step [100/773], Loss: 0.0000\n",
            "Epoch [16/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [16/25], Step [300/773], Loss: 0.0000\n",
            "Epoch [16/25], Step [400/773], Loss: 0.0000\n",
            "Epoch [16/25], Step [500/773], Loss: 0.0000\n",
            "Epoch [16/25], Step [600/773], Loss: 0.0000\n",
            "Epoch [16/25], Step [700/773], Loss: 0.0003\n",
            "train loss at epoch 15 is 2.140137550440774e-05\n",
            "Epoch [17/25], Step [100/773], Loss: 0.0000\n",
            "Epoch [17/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [17/25], Step [300/773], Loss: 0.0000\n",
            "Epoch [17/25], Step [400/773], Loss: 0.0000\n",
            "Epoch [17/25], Step [500/773], Loss: 0.0000\n",
            "Epoch [17/25], Step [600/773], Loss: 0.0000\n",
            "Epoch [17/25], Step [700/773], Loss: 0.0000\n",
            "train loss at epoch 16 is 1.8113538416098463e-05\n",
            "Epoch [18/25], Step [100/773], Loss: 0.0000\n",
            "Epoch [18/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [18/25], Step [300/773], Loss: 0.0000\n",
            "Epoch [18/25], Step [400/773], Loss: 0.0000\n",
            "Epoch [18/25], Step [500/773], Loss: 0.0000\n",
            "Epoch [18/25], Step [600/773], Loss: 0.0000\n",
            "Epoch [18/25], Step [700/773], Loss: 0.0000\n",
            "train loss at epoch 17 is 1.7281140518921578e-05\n",
            "Epoch [19/25], Step [100/773], Loss: 0.0000\n",
            "Epoch [19/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [19/25], Step [300/773], Loss: 0.0000\n",
            "Epoch [19/25], Step [400/773], Loss: 0.0000\n",
            "Epoch [19/25], Step [500/773], Loss: 0.0000\n",
            "Epoch [19/25], Step [600/773], Loss: 0.0000\n",
            "Epoch [19/25], Step [700/773], Loss: 0.0000\n",
            "train loss at epoch 18 is 1.7536098800400705e-05\n",
            "Epoch [20/25], Step [100/773], Loss: 0.0000\n",
            "Epoch [20/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [20/25], Step [300/773], Loss: 0.0000\n",
            "Epoch [20/25], Step [400/773], Loss: 0.0000\n",
            "Epoch [20/25], Step [500/773], Loss: 0.0000\n",
            "Epoch [20/25], Step [600/773], Loss: 0.0000\n",
            "Epoch [20/25], Step [700/773], Loss: 0.2012\n",
            "train loss at epoch 19 is 0.013670357416795002\n",
            "Epoch [21/25], Step [100/773], Loss: 0.0077\n",
            "Epoch [21/25], Step [200/773], Loss: 0.0002\n",
            "Epoch [21/25], Step [300/773], Loss: 0.0002\n",
            "Epoch [21/25], Step [400/773], Loss: 0.0069\n",
            "Epoch [21/25], Step [500/773], Loss: 0.0001\n",
            "Epoch [21/25], Step [600/773], Loss: 0.0001\n",
            "Epoch [21/25], Step [700/773], Loss: 0.0000\n",
            "train loss at epoch 20 is 0.0031876233506921148\n",
            "Epoch [22/25], Step [100/773], Loss: 0.0001\n",
            "Epoch [22/25], Step [200/773], Loss: 0.0001\n",
            "Epoch [22/25], Step [300/773], Loss: 0.0000\n",
            "Epoch [22/25], Step [400/773], Loss: 0.0001\n",
            "Epoch [22/25], Step [500/773], Loss: 0.0000\n",
            "Epoch [22/25], Step [600/773], Loss: 0.0001\n",
            "Epoch [22/25], Step [700/773], Loss: 0.0000\n",
            "train loss at epoch 21 is 6.909990476541483e-05\n",
            "Epoch [23/25], Step [100/773], Loss: 0.0000\n",
            "Epoch [23/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [23/25], Step [300/773], Loss: 0.0001\n",
            "Epoch [23/25], Step [400/773], Loss: 0.0004\n",
            "Epoch [23/25], Step [500/773], Loss: 0.0001\n",
            "Epoch [23/25], Step [600/773], Loss: 0.0001\n",
            "Epoch [23/25], Step [700/773], Loss: 0.0001\n",
            "train loss at epoch 22 is 3.637027323752161e-05\n",
            "Epoch [24/25], Step [100/773], Loss: 0.0000\n",
            "Epoch [24/25], Step [200/773], Loss: 0.0000\n",
            "Epoch [24/25], Step [300/773], Loss: 0.0001\n",
            "Epoch [24/25], Step [400/773], Loss: 0.0000\n",
            "Epoch [24/25], Step [500/773], Loss: 0.0000\n",
            "Epoch [24/25], Step [600/773], Loss: 0.0000\n",
            "Epoch [24/25], Step [700/773], Loss: 0.0000\n",
            "train loss at epoch 23 is 2.5081953872819344e-05\n",
            "Got 2746 / 2746 with accuracy 100.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=CNN()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "model.eval()\n",
        "valid_fn(model,optimizer,val_loader,loss_fn,DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upDh7Xjmpgb_",
        "outputId": "6e7e638c-be1c-418e-96d3-c33dd0d67f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 2746 / 2746 with accuracy 100.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test[\"id\"]=[i for i in range(test.shape[0])]"
      ],
      "metadata": {
        "id": "qe_KcG9rv2f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "TR7kFsSvyXOA",
        "outputId": "94e24e95-38a7-4ce9-ec8b-15b091aae07a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0         6     149     149     150     150     150     151     151     150   \n",
              "1         5     126     128     131     132     133     134     135     135   \n",
              "2        10      85      88      92      96     105     123     135     143   \n",
              "3         0     203     205     207     206     207     209     210     209   \n",
              "4         3     188     191     193     195     199     201     202     203   \n",
              "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "7167      1     135     119     108     102     105      99      61     103   \n",
              "7168     12     157     159     161     164     166     166     171     174   \n",
              "7169      2     190     191     190     191     190     190     192     192   \n",
              "7170      4     201     205     208     209     214     216     218     223   \n",
              "7171      2     173     174     173     174     173     173     175     175   \n",
              "\n",
              "      pixel9  ...  pixel776  pixel777  pixel778  pixel779  pixel780  pixel781  \\\n",
              "0        151  ...       148       127        89        82        96       106   \n",
              "1        136  ...       104       194       183       186       184       184   \n",
              "2        147  ...       166       242       227       230       227       226   \n",
              "3        210  ...       248       247       248       253       236       230   \n",
              "4        203  ...        40        64        48        29        46        49   \n",
              "...      ...  ...       ...       ...       ...       ...       ...       ...   \n",
              "7167     121  ...       112       116       114       118       180       184   \n",
              "7168     175  ...       213       213       214       213       211       210   \n",
              "7169     191  ...       215       213       214       214       213       210   \n",
              "7170     226  ...       169       255       255       237       113        91   \n",
              "7171     174  ...       200       197       198       198       197       195   \n",
              "\n",
              "      pixel782  pixel783  pixel784    id  \n",
              "0          112       120       107     0  \n",
              "1          184       182       180     1  \n",
              "2          225       224       222     2  \n",
              "3          240       253       255     3  \n",
              "4           46        46        53     4  \n",
              "...        ...       ...       ...   ...  \n",
              "7167       176       167       163  7167  \n",
              "7168       210       209       208  7168  \n",
              "7169       211       209       208  7169  \n",
              "7170        67        70        63  7170  \n",
              "7171       195       193       192  7171  \n",
              "\n",
              "[7172 rows x 786 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-607a7ca6-5d90-4b3b-acd4-8b45ce78b14a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>149</td>\n",
              "      <td>149</td>\n",
              "      <td>150</td>\n",
              "      <td>150</td>\n",
              "      <td>150</td>\n",
              "      <td>151</td>\n",
              "      <td>151</td>\n",
              "      <td>150</td>\n",
              "      <td>151</td>\n",
              "      <td>...</td>\n",
              "      <td>148</td>\n",
              "      <td>127</td>\n",
              "      <td>89</td>\n",
              "      <td>82</td>\n",
              "      <td>96</td>\n",
              "      <td>106</td>\n",
              "      <td>112</td>\n",
              "      <td>120</td>\n",
              "      <td>107</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>126</td>\n",
              "      <td>128</td>\n",
              "      <td>131</td>\n",
              "      <td>132</td>\n",
              "      <td>133</td>\n",
              "      <td>134</td>\n",
              "      <td>135</td>\n",
              "      <td>135</td>\n",
              "      <td>136</td>\n",
              "      <td>...</td>\n",
              "      <td>104</td>\n",
              "      <td>194</td>\n",
              "      <td>183</td>\n",
              "      <td>186</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>182</td>\n",
              "      <td>180</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>85</td>\n",
              "      <td>88</td>\n",
              "      <td>92</td>\n",
              "      <td>96</td>\n",
              "      <td>105</td>\n",
              "      <td>123</td>\n",
              "      <td>135</td>\n",
              "      <td>143</td>\n",
              "      <td>147</td>\n",
              "      <td>...</td>\n",
              "      <td>166</td>\n",
              "      <td>242</td>\n",
              "      <td>227</td>\n",
              "      <td>230</td>\n",
              "      <td>227</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>224</td>\n",
              "      <td>222</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>203</td>\n",
              "      <td>205</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>207</td>\n",
              "      <td>209</td>\n",
              "      <td>210</td>\n",
              "      <td>209</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>248</td>\n",
              "      <td>247</td>\n",
              "      <td>248</td>\n",
              "      <td>253</td>\n",
              "      <td>236</td>\n",
              "      <td>230</td>\n",
              "      <td>240</td>\n",
              "      <td>253</td>\n",
              "      <td>255</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>188</td>\n",
              "      <td>191</td>\n",
              "      <td>193</td>\n",
              "      <td>195</td>\n",
              "      <td>199</td>\n",
              "      <td>201</td>\n",
              "      <td>202</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>64</td>\n",
              "      <td>48</td>\n",
              "      <td>29</td>\n",
              "      <td>46</td>\n",
              "      <td>49</td>\n",
              "      <td>46</td>\n",
              "      <td>46</td>\n",
              "      <td>53</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7167</th>\n",
              "      <td>1</td>\n",
              "      <td>135</td>\n",
              "      <td>119</td>\n",
              "      <td>108</td>\n",
              "      <td>102</td>\n",
              "      <td>105</td>\n",
              "      <td>99</td>\n",
              "      <td>61</td>\n",
              "      <td>103</td>\n",
              "      <td>121</td>\n",
              "      <td>...</td>\n",
              "      <td>112</td>\n",
              "      <td>116</td>\n",
              "      <td>114</td>\n",
              "      <td>118</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>176</td>\n",
              "      <td>167</td>\n",
              "      <td>163</td>\n",
              "      <td>7167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7168</th>\n",
              "      <td>12</td>\n",
              "      <td>157</td>\n",
              "      <td>159</td>\n",
              "      <td>161</td>\n",
              "      <td>164</td>\n",
              "      <td>166</td>\n",
              "      <td>166</td>\n",
              "      <td>171</td>\n",
              "      <td>174</td>\n",
              "      <td>175</td>\n",
              "      <td>...</td>\n",
              "      <td>213</td>\n",
              "      <td>213</td>\n",
              "      <td>214</td>\n",
              "      <td>213</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>209</td>\n",
              "      <td>208</td>\n",
              "      <td>7168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7169</th>\n",
              "      <td>2</td>\n",
              "      <td>190</td>\n",
              "      <td>191</td>\n",
              "      <td>190</td>\n",
              "      <td>191</td>\n",
              "      <td>190</td>\n",
              "      <td>190</td>\n",
              "      <td>192</td>\n",
              "      <td>192</td>\n",
              "      <td>191</td>\n",
              "      <td>...</td>\n",
              "      <td>215</td>\n",
              "      <td>213</td>\n",
              "      <td>214</td>\n",
              "      <td>214</td>\n",
              "      <td>213</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>209</td>\n",
              "      <td>208</td>\n",
              "      <td>7169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7170</th>\n",
              "      <td>4</td>\n",
              "      <td>201</td>\n",
              "      <td>205</td>\n",
              "      <td>208</td>\n",
              "      <td>209</td>\n",
              "      <td>214</td>\n",
              "      <td>216</td>\n",
              "      <td>218</td>\n",
              "      <td>223</td>\n",
              "      <td>226</td>\n",
              "      <td>...</td>\n",
              "      <td>169</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>237</td>\n",
              "      <td>113</td>\n",
              "      <td>91</td>\n",
              "      <td>67</td>\n",
              "      <td>70</td>\n",
              "      <td>63</td>\n",
              "      <td>7170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7171</th>\n",
              "      <td>2</td>\n",
              "      <td>173</td>\n",
              "      <td>174</td>\n",
              "      <td>173</td>\n",
              "      <td>174</td>\n",
              "      <td>173</td>\n",
              "      <td>173</td>\n",
              "      <td>175</td>\n",
              "      <td>175</td>\n",
              "      <td>174</td>\n",
              "      <td>...</td>\n",
              "      <td>200</td>\n",
              "      <td>197</td>\n",
              "      <td>198</td>\n",
              "      <td>198</td>\n",
              "      <td>197</td>\n",
              "      <td>195</td>\n",
              "      <td>195</td>\n",
              "      <td>193</td>\n",
              "      <td>192</td>\n",
              "      <td>7171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7172 rows Ã— 786 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-607a7ca6-5d90-4b3b-acd4-8b45ce78b14a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-607a7ca6-5d90-4b3b-acd4-8b45ce78b14a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-607a7ca6-5d90-4b3b-acd4-8b45ce78b14a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class test_dataset(Dataset):\n",
        "  def __init__(self,data,transform=False):\n",
        "      super().__init__()\n",
        "      self.data=data\n",
        "      self.transform=transform\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.data.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        features=self.data.iloc[:,1:-1].values[index].reshape(1,28,28)\n",
        "       \n",
        "        if self.transform:\n",
        "          features=self.standard(features)\n",
        "          features=torch.from_numpy(features)\n",
        "        return features\n",
        "  def standard(self,x): #x:torch.float64\n",
        "        return ((x-159.29)/48.76)"
      ],
      "metadata": {
        "id": "oLkCd1i1yKcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlsUTUeB1wBY",
        "outputId": "fdb89351-a986-45ac-8d4f-73778a1932e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RangeIndex(start=0, stop=7172, step=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_=test_dataset(test,transform=True)\n",
        "test_loader=DataLoader(test_,batch_size=32,shuffle=False)\n",
        "\n",
        "model=CNN()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "prediction=[]\n",
        "prediction_ar=np.zeros((test.shape[0],1))\n",
        "for x in test_loader:\n",
        "  model.to(DEVICE)\n",
        "  model.eval()\n",
        "  x=(x.type(dtype)).to(DEVICE)\n",
        "  pred=model(x)\n",
        "  prediction.append(pred.detach().numpy())\n",
        "prediction=np.concatenate(prediction)\n",
        "prediction_ar=prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "FChJAxHazVIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m=torch.nn.Softmax(dim=1)\n",
        "p=m(torch.from_numpy(prediction_ar)).argmax(dim=1)\n",
        "p.to('cpu').numpy()\n",
        "test[\"pred\"]=p.to('cpu').numpy()"
      ],
      "metadata": {
        "id": "sdwXukW-A6rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "4rnLtG5kCUEE",
        "outputId": "812c5f3c-81bc-4475-aa36-bfacd193be2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0         6     149     149     150     150     150     151     151     150   \n",
              "1         5     126     128     131     132     133     134     135     135   \n",
              "2        10      85      88      92      96     105     123     135     143   \n",
              "3         0     203     205     207     206     207     209     210     209   \n",
              "4         3     188     191     193     195     199     201     202     203   \n",
              "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "7167      1     135     119     108     102     105      99      61     103   \n",
              "7168     12     157     159     161     164     166     166     171     174   \n",
              "7169      2     190     191     190     191     190     190     192     192   \n",
              "7170      4     201     205     208     209     214     216     218     223   \n",
              "7171      2     173     174     173     174     173     173     175     175   \n",
              "\n",
              "      pixel9  ...  pixel777  pixel778  pixel779  pixel780  pixel781  pixel782  \\\n",
              "0        151  ...       127        89        82        96       106       112   \n",
              "1        136  ...       194       183       186       184       184       184   \n",
              "2        147  ...       242       227       230       227       226       225   \n",
              "3        210  ...       247       248       253       236       230       240   \n",
              "4        203  ...        64        48        29        46        49        46   \n",
              "...      ...  ...       ...       ...       ...       ...       ...       ...   \n",
              "7167     121  ...       116       114       118       180       184       176   \n",
              "7168     175  ...       213       214       213       211       210       210   \n",
              "7169     191  ...       213       214       214       213       210       211   \n",
              "7170     226  ...       255       255       237       113        91        67   \n",
              "7171     174  ...       197       198       198       197       195       195   \n",
              "\n",
              "      pixel783  pixel784    id  pred  \n",
              "0          120       107     0     6  \n",
              "1          182       180     1     5  \n",
              "2          224       222     2    10  \n",
              "3          253       255     3     0  \n",
              "4           46        53     4     3  \n",
              "...        ...       ...   ...   ...  \n",
              "7167       167       163  7167     1  \n",
              "7168       209       208  7168    12  \n",
              "7169       209       208  7169     2  \n",
              "7170        70        63  7170     4  \n",
              "7171       193       192  7171     2  \n",
              "\n",
              "[7172 rows x 787 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-423887c9-71b5-43a6-9dc6-ee77a6901aa8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "      <th>id</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>149</td>\n",
              "      <td>149</td>\n",
              "      <td>150</td>\n",
              "      <td>150</td>\n",
              "      <td>150</td>\n",
              "      <td>151</td>\n",
              "      <td>151</td>\n",
              "      <td>150</td>\n",
              "      <td>151</td>\n",
              "      <td>...</td>\n",
              "      <td>127</td>\n",
              "      <td>89</td>\n",
              "      <td>82</td>\n",
              "      <td>96</td>\n",
              "      <td>106</td>\n",
              "      <td>112</td>\n",
              "      <td>120</td>\n",
              "      <td>107</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>126</td>\n",
              "      <td>128</td>\n",
              "      <td>131</td>\n",
              "      <td>132</td>\n",
              "      <td>133</td>\n",
              "      <td>134</td>\n",
              "      <td>135</td>\n",
              "      <td>135</td>\n",
              "      <td>136</td>\n",
              "      <td>...</td>\n",
              "      <td>194</td>\n",
              "      <td>183</td>\n",
              "      <td>186</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>182</td>\n",
              "      <td>180</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>85</td>\n",
              "      <td>88</td>\n",
              "      <td>92</td>\n",
              "      <td>96</td>\n",
              "      <td>105</td>\n",
              "      <td>123</td>\n",
              "      <td>135</td>\n",
              "      <td>143</td>\n",
              "      <td>147</td>\n",
              "      <td>...</td>\n",
              "      <td>242</td>\n",
              "      <td>227</td>\n",
              "      <td>230</td>\n",
              "      <td>227</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>224</td>\n",
              "      <td>222</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>203</td>\n",
              "      <td>205</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>207</td>\n",
              "      <td>209</td>\n",
              "      <td>210</td>\n",
              "      <td>209</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>247</td>\n",
              "      <td>248</td>\n",
              "      <td>253</td>\n",
              "      <td>236</td>\n",
              "      <td>230</td>\n",
              "      <td>240</td>\n",
              "      <td>253</td>\n",
              "      <td>255</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>188</td>\n",
              "      <td>191</td>\n",
              "      <td>193</td>\n",
              "      <td>195</td>\n",
              "      <td>199</td>\n",
              "      <td>201</td>\n",
              "      <td>202</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>...</td>\n",
              "      <td>64</td>\n",
              "      <td>48</td>\n",
              "      <td>29</td>\n",
              "      <td>46</td>\n",
              "      <td>49</td>\n",
              "      <td>46</td>\n",
              "      <td>46</td>\n",
              "      <td>53</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7167</th>\n",
              "      <td>1</td>\n",
              "      <td>135</td>\n",
              "      <td>119</td>\n",
              "      <td>108</td>\n",
              "      <td>102</td>\n",
              "      <td>105</td>\n",
              "      <td>99</td>\n",
              "      <td>61</td>\n",
              "      <td>103</td>\n",
              "      <td>121</td>\n",
              "      <td>...</td>\n",
              "      <td>116</td>\n",
              "      <td>114</td>\n",
              "      <td>118</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>176</td>\n",
              "      <td>167</td>\n",
              "      <td>163</td>\n",
              "      <td>7167</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7168</th>\n",
              "      <td>12</td>\n",
              "      <td>157</td>\n",
              "      <td>159</td>\n",
              "      <td>161</td>\n",
              "      <td>164</td>\n",
              "      <td>166</td>\n",
              "      <td>166</td>\n",
              "      <td>171</td>\n",
              "      <td>174</td>\n",
              "      <td>175</td>\n",
              "      <td>...</td>\n",
              "      <td>213</td>\n",
              "      <td>214</td>\n",
              "      <td>213</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>209</td>\n",
              "      <td>208</td>\n",
              "      <td>7168</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7169</th>\n",
              "      <td>2</td>\n",
              "      <td>190</td>\n",
              "      <td>191</td>\n",
              "      <td>190</td>\n",
              "      <td>191</td>\n",
              "      <td>190</td>\n",
              "      <td>190</td>\n",
              "      <td>192</td>\n",
              "      <td>192</td>\n",
              "      <td>191</td>\n",
              "      <td>...</td>\n",
              "      <td>213</td>\n",
              "      <td>214</td>\n",
              "      <td>214</td>\n",
              "      <td>213</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>209</td>\n",
              "      <td>208</td>\n",
              "      <td>7169</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7170</th>\n",
              "      <td>4</td>\n",
              "      <td>201</td>\n",
              "      <td>205</td>\n",
              "      <td>208</td>\n",
              "      <td>209</td>\n",
              "      <td>214</td>\n",
              "      <td>216</td>\n",
              "      <td>218</td>\n",
              "      <td>223</td>\n",
              "      <td>226</td>\n",
              "      <td>...</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>237</td>\n",
              "      <td>113</td>\n",
              "      <td>91</td>\n",
              "      <td>67</td>\n",
              "      <td>70</td>\n",
              "      <td>63</td>\n",
              "      <td>7170</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7171</th>\n",
              "      <td>2</td>\n",
              "      <td>173</td>\n",
              "      <td>174</td>\n",
              "      <td>173</td>\n",
              "      <td>174</td>\n",
              "      <td>173</td>\n",
              "      <td>173</td>\n",
              "      <td>175</td>\n",
              "      <td>175</td>\n",
              "      <td>174</td>\n",
              "      <td>...</td>\n",
              "      <td>197</td>\n",
              "      <td>198</td>\n",
              "      <td>198</td>\n",
              "      <td>197</td>\n",
              "      <td>195</td>\n",
              "      <td>195</td>\n",
              "      <td>193</td>\n",
              "      <td>192</td>\n",
              "      <td>7171</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7172 rows Ã— 787 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-423887c9-71b5-43a6-9dc6-ee77a6901aa8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-423887c9-71b5-43a6-9dc6-ee77a6901aa8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-423887c9-71b5-43a6-9dc6-ee77a6901aa8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((test['label']==test['pred']).sum())\n",
        "print(test.shape[0])\n",
        "acc=((test['label']==test['pred']).sum())/test.shape[0]\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6ebGgH7Crdu",
        "outputId": "03619d36-f4fa-498b-95a5-4cdc33f4e39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6685\n",
            "7172\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9320970440602342"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    }
  ]
}